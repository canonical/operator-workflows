name: Tests

on:
  workflow_call:
    inputs:
        tox-ini-dir:
          type: string
          description: Path to tox.ini file
          default: './'

jobs:
  inclusive-naming-check:
    name: Inclusive naming
    runs-on: ubuntu-22.04
    steps:
      - uses: actions/checkout@v3
        with:
          repository: canonical/Inclusive-naming
      - run: mv * /tmp
      - uses: actions/checkout@v3
      - name: Merge configuration files
        run: |
          # Combine all entries and replace matching elements by
          # .name in .rules for the ones in .woke.yaml
          woke_file=""
          if [ -f .woke.yaml ]; then
            woke_file=".woke.yaml"
          elif [ -f .woke.yml ]; then
            woke_file=".woke.yml"
          fi
          if [ ! -z "$woke_file" ]; then
            yq eval-all '
            (
              . as $item ireduce ({}; . *+ $item) | .rules | unique_by(.name)
            ) as $mergedArray | . as $item ireduce ({}; . *+ $item) | .rules = $mergedArray
            ' $woke_file /tmp/config.yml | tee /tmp/merged.yml
            mv /tmp/merged.yml /tmp/config.yml
          fi
      - name: Run inclusive naming check
        uses: canonical/inclusive-naming@main
        with:
          fail-on-error: "true"
          github-token: ${{ secrets.GITHUB_TOKEN }}
          reporter: github-pr-review
          woke-args: '. -c /tmp/config.yml'
          filter-mode: nofilter
  get-runner-image:
    name: Get runner image
    uses: ./.github/workflows/get_runner_image.yaml
  shellcheck-lint:
    name: Shell scripts lint
    runs-on: ubuntu-22.04
    steps:
      - uses: actions/checkout@v3
      - name: Gather files to scan
        shell: bash
        id: gather
        run: |
          declare -a filepaths
          shebangregex="^#! */[^ ]*/(env *)?[abk]*sh"

          set -f # temporarily disable globbing so that globs in inputs aren't expanded

          while IFS= read -r -d '' file; do
          filepaths+=("$file")
          done < <(find . \
                        -type f \
                        '(' \
                        -name '*.bash' \
                        -o -name '.bashrc' \
                        -o -name 'bashrc' \
                        -o -name '.bash_aliases' \
                        -o -name '.bash_completion' \
                        -o -name '.bash_login' \
                        -o -name '.bash_logout' \
                        -o -name '.bash_profile' \
                        -o -name 'bash_profile' \
                        -o -name '*.ksh' \
                        -o -name 'suid_profile' \
                        -o -name '*.zsh' \
                        -o -name '.zlogin' \
                        -o -name 'zlogin' \
                        -o -name '.zlogout' \
                        -o -name 'zlogout' \
                        -o -name '.zprofile' \
                        -o -name 'zprofile' \
                        -o -name '.zsenv' \
                        -o -name 'zsenv' \
                        -o -name '.zshrc' \
                        -o -name 'zshrc' \
                        -o -name '*.sh' \
                        -o -path '*/.profile' \
                        -o -path '*/profile' \
                        -o -name '*.shlib' \
                        ')' \
                        -print0)

          while IFS= read -r -d '' file; do
          head -n1 "$file" | grep -Eqs "$shebangregex" || continue
          filepaths+=("$file")
          done < <(find . \
                        -type f ! -name '*.*' -perm /111 \
                        -print0)
          echo "filepaths=${filepaths[@]}" >> $GITHUB_OUTPUT
          set +f # re-enable globbing
      - if: ${{ steps.gather.outputs.filepaths != '' }}
        name: Shellcheck Problem Matchers
        uses: lumaxis/shellcheck-problem-matchers@v1.1.2
      - if: ${{ steps.gather.outputs.filepaths != '' }}
        run: shellcheck -f gcc ${{steps.gather.outputs.filepaths}}
  docker-lint:
    name: Dockerfile lint
    runs-on: ubuntu-22.04
    steps:
      - uses: actions/checkout@v3
      - name: Check for Dockerfiles
        run: echo Dockerfiles=$(find . -name "*Dockerfile") >> $GITHUB_ENV
      - if: ${{ env.Dockerfiles != '' }}
        name: Run HadoLint
        uses: jbergstroem/hadolint-gh-action@v1
        with:
          dockerfile: "${{ env.Dockerfiles }}"
  lint-metadata:
    name: Lint metadata.yaml
    runs-on: ubuntu-22.04
    steps:
      - uses: actions/checkout@v3
      - name: Install check-jsonschema
        run: python3 -m pip install check-jsonschema
      - name: Download schema
        run: curl -fLsSo $PWD/metadata.schema https://raw.githubusercontent.com/canonical/operator-workflows/main/.github/files/metadata.schema
      - name: Run lint
        run: check-jsonschema metadata.yaml --schemafile metadata.schema
  lint-and-unit-test:
    name: Lint and unit tests
    runs-on: ${{ needs.get-runner-image.outputs.runs-on }}
    needs: get-runner-image
    steps:
      - uses: actions/checkout@v3
      - name: Install tox
        run: python3 -m pip install tox
      - name: Run tests
        run: tox --result-json=test-result.json -c ${{ inputs.tox-ini-dir }}
      - name: Export test report
        if: always()
        uses: actions/github-script@v6.2.0
        with:
          script: |
            const no_color = (text) => {
                return text.replace(/[\u001b\u009b][[()#;?]*(?:[0-9]{1,4}(?:;[0-9]{0,4})*)?[0-9A-ORZcf-nqry=><]/g, '');
            }

            const sha = '${{ github.event.pull_request.head.sha }}';
            const fs = require('fs');
            const result = JSON.parse(fs.readFileSync('test-result.json')).testenvs;

            let lint_result = result.lint.test;
            let lint_success = true;
            let lint_output = '';
            for (let lint_test_result of lint_result) {
              if (lint_test_result.retcode != 0) {
                lint_success = false;
              }
              if (lint_test_result.output) {
                lint_output += lint_test_result.output;
              }
            }
            let unit_result = result.unit.test;
            let unit_success = unit_result[0].retcode == 0;
            let unit_output = unit_result[0].output;
            let static_result = result.static.test;
            let static_output = static_result[0].output;
            let coverage_result = result["coverage-report"].test;
            let coverage_output = coverage_result[0].output;

            let reports = [];
            if (!lint_success) {
              reports.push(
                `Lint checks failed for ${sha}\n
                \`\`\`\n${no_color(lint_output).trim()}\n\`\`\``
              );
            }
            if (!unit_success) {
              reports.push(
                `Unit tests failed for ${sha}\n
                \`\`\`\n${no_color(unit_output).trim()}\n\`\`\``
              );
            }
            reports.push(
              `Test coverage for ${sha}\n
              \`\`\`\n${no_color(coverage_output).trim()}\n\`\`\`
              Static code analysis report\n
              \`\`\`\n${no_color(static_output).trim()}\n\`\`\``
            );
            let json = JSON.stringify(reports);
            fs.writeFileSync('report.json', json);
      - name: Upload coverage report
        uses: actions/upload-artifact@v3
        if: always() && github.event_name == 'pull_request'
        with:
          name: report
          path: report.json
  draft-publish-docs:
    name: Draft publish docs
    runs-on: ubuntu-22.04
    steps:
      - uses: actions/checkout@v3
      - name: Search for docs folder
        id: docs-exist
        run: echo "docs_exist=$([[ -d docs ]] && echo 'True' || echo 'False')" >> $GITHUB_OUTPUT
      - name: Publish documentation
        if: steps.docs-exist.outputs.docs_exist == 'True'
        uses: canonical/upload-charm-docs@main
        with:
          discourse_host: discourse.charmhub.io
          discourse_api_username: ${{ secrets.DISCOURSE_API_USERNAME }}
          discourse_api_key: ${{ secrets.DISCOURSE_API_KEY }}
          dry_run: true
